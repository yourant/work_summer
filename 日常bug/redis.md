# 分布式锁
实现逻辑

1. 在执行函数时先判断是否有特殊key的缓存数据存在

2. 如果不存在特殊key的缓存数据, 则新建, 如果存在, 则 sleep然后继续检查, 超过一定检查次数报错, 并且将该key 和任务执行信息, 保存下来并且以某种方式通知到具体人

3. 在函数执行完成后需要删除该特殊key, 这样后面的任务就能执行
   
# 主从模式
> 此种模式下, 能实现redis的容灾备份 和 读写分离

### 主从模式全量同步
> slave节点发起全量同步, 当master节点收到全量同步命令后开始执行BGSAVE, 并且将开始执行BGSAVE之后发生变更的数据写入缓冲区, 当BGSAVE执行完成之后,将rdb文件发送到slave节点, 发送完成后继续发送缓冲区中的数据,slave节点收到新的rdb文件后会丢弃所有旧数据并且载入新收到的rdb文件, 当rdb载入完成后, 开始写入发送过来的缓冲区记录

### 主从模式增量同步
> 全量同步完成之后, 后续master节点收到写入命令, 就会自动同步到slave 节点, 以此保证数据一致性


### 容灾备份

> 使用 slave 节点 实现 redis 的 持久化存储 AOF 或 RDB, 以此来减轻master服务的负载, 当master节点出现不可预知的错误导致 数据丢失, 可以从slave找到原数据的备份 以此来恢复数据, slave 节点使用 AOF (追加日志) 或者是 RDB (镜像文件)的方式来持久化存储, 一般来讲会二者结合使用

#### RDB 
```
BGSAVE (fork子进程)
SAVE (不会fork子进程, 导致当前服务阻塞)

先将数据集写入一个临时文件, 当快照执行完成后再覆盖原来的rdb文件,用二进制压缩存储
配置如下 save 900 1 , 每900s检查一次, 有一个key对应的数据发生改变则做以此快照, 以上一次执行快照为 数据改变检查点, 也可以手动执行备份(BGSAVE和SAVE), 数据恢复时会相对较快
```
#### AOF
appendfsync 配置 always(每次写操作执行日志写入), no(不执行) , everysec(每一秒执行一次), 以追加的方式写入日志文件

对服务性能会有一定影响, 需要权衡服务器性能和数据准确性


### 读写分离


1. master节点支持读写操作, 写(增删改), slave 只读, 然后只能同步master节点的写操作
2. 一台master可以配置多台 slave
3. master 宕机后不影响 slave的读取, 但是该集群不在支持写入, slave宕机后不影响master, 也就是master宕机后不会从slave中选举新的master
4. 读取数据可以从不同的 slave 节点中获取数据, 写数据只依赖master节点, 所以当 qps 很高例如达到 10w+, 就可以使用读写分离的方式来支撑

# 哨兵模式

> 在主从模式下, 当master节点宕机后, 不会从slave中选举master,所以集群丧失了写的能力, 我们只能人工将slave节点升级为master, 并且要通知应用方更新master节点的 (ip:port), 这种方式是难以让人接受的, 所以从redis2.8版本开始, redis 正式提供了哨兵模式的架构来解决这个问题

### 工作特点

1. 建立在主从模式的基础上, 当master节点宕机之后, 哨兵会从slave节点中选择一个节点作为master
2. 原先宕机的master节点重新启动, 将不再是master, 而是作为新master的一个slave 节点
3. 哨兵节点是一个redis 节点,本质上也是一个进程, 所以也有挂掉的可能, 所以哨兵也存在集群模式

### 工作原理
- 每隔10秒,每个哨兵节点会向master和slave发送 info获取最新的**拓扑结构**
- 每隔1秒,每个哨兵节点向master和slave还有其他哨兵节点发送ping命令做**心跳检测**,看是否存在不可达节点
- 当哨兵发送的心跳检测没有得到响应, 那么该哨兵认为该节点已经下线, 某个哨兵**主观**上认为该节点已经**下线**后会询问其他哨兵该节点是否下线,当判定为下线的哨兵达到一定数目, 该节点为**客观下线**
- 当master节点被客观下线后, 各个哨兵节点会选举一个领导者哨兵, 由该节点对 master 节点进行故障转移, 哨兵节点选择与主节点数据相似度最高的slave节点作为新的master节点
- **故障转移**, 当master节点下线后, 哨兵节点从slave节点选举一个新的master节点, 并且还会监控下线的master节点,当它回复后作为新master节点的slave节点, 并且同步新master节点的数据
- 当使用哨兵模式时, 客户端不直接连Redis, 而是连接哨兵的ip和port, 由哨兵来提供具体redis, 这样当master挂掉后, 哨兵就会感知并提供master节点给使用者


# Cluster模式
> 在哨兵模式中, 引入了主节点的自动故障转移, 进一步提高了Redis的高可用性, 但是哨兵模式的权限同样很明显, 哨兵无法对Slave节点进行自动故障转移, 在读写分离的场景, Slave故障会导致读服务不可用, 需要我们对Slave 做额外的监控, 切换操作
> 此外哨兵模式没有解决操作无法负载均衡, 及存储能力受到单机限制的问题, Redis3.0 后推荐使用Redis Cluster模式, 这种集群模式没有中心节点, 可水平扩展, 而且集群配置非常简单

### 工作特点
1. 多个Redis节点互联, 数据共享
2. 所有节点都是主从模式, **其中Slave节点不提供服务, 只提供备用**
3. 不支持同时处理多个Key, 需要分发到多个节点上
4. 支持在线增加, 删除节点 (动态扩容)
5. 客户端可以连接到任何一个Master节点进行读写, 集群内部会自动实现负载均衡

### 工作原理

- Redis Cluster有固定的16384个hash slot(槽), 对每个key计算CRC16值, 对16384取模, 可以获取key 对应的 hash slot
, 每个master都会持有部分slot, 比如有3 个master, 那么可能每个master持有5000多个hash slot, 将写入或者读取请求发送到任意master节点上, 每个master都会对其 key 计算 CRC16 值, 然后对16384 取模, 获取到对应的hash slot, 然后确定key绑定到哪个 master节点, 然后进行存数或者取数操作
- **主观下线**, 每个节点之间会定期相互ping, 如果在一段时间内持续ping 失败, 则发送节点认为接收节点存在故障, 会把该节点判定为主观下线
- **客观下线**, 当判断某个节点主观下线后, 发送节点会把该接收节点的下线状态在集群中传播, {"node1": [{"node3": "失败"}], "node2": [{"node3": "失败"}]}

- **故障转移**, slave节点出现问题不会影响业务, 当master节点出现宕机, 会由其他master节点选举一个, 宕机slave 节点顶上去


# Redis的单线程
1. redis 是使用**单进程单线程**模型的 kv数据库, redis 是一个内存数据库, 所有的运算都是内存级别的运算, 所以要小心使用redis 时间复杂度 为O(n)的指令, 例如 scan, 可能会导致系统卡顿
2. 由于是单线程, 避免了线程切换带来的性能损耗
3. 网络io 的多路复用, 事件轮询 API, 非阻塞IO

### 多路复用

> 多路是指多个socket, 复用是指 使用一个线程, 多路复用, 事件轮询api, select, poll, epoll, 现在多是用epoll,
> select 连接数受限, 事先声明了轮询列表长度
> 查找匹配速度慢
> 数据由内核拷贝到用户态
select 和 poll 都是轮询所有的 fd(文件句柄), 不管有没有收到数据, 
epoll 会将当前收到事件的fd 写入一个队列, 然后轮询队列, 使得轮询效率有很大提升

epoll的三个函数
1. 创建 epoll 句柄
2. 事件注册函数
3. 事件等待函数

### 非阻塞io

> socket默认的读写方法都是 阻塞的, read 方法 要传递一个参数n 进去, 如果没有读够 n 个字节, 线程就会卡在那里, write方法 一般不会阻塞, 除非内核为套接字分配的
> 写缓冲区已经满了,write 方法就会阻塞, 直到缓冲区中有空闲空间挪出来, **非阻塞**的 io 在socket 提供了一个选项Non_Blocking, 这个方法打开时,读写方法不会阻塞,由于有了非阻塞io, 单线程在读写io 时, 不必再阻塞, 可以瞬间完成, 然后做其他事情